import json
import os

import numpy as np
import torch
from torch.utils.data import DataLoader, Dataset
from typing import Tuple, List
from util import get_dc_offset

RANDOM_SPLIT_SEED = 0


class PoseEstimation6DDataset(Dataset):
    def __init__(
        self,
        dset_path: str,
        dset_type: str,
        split: str,
        test_portion: float = 0.2,
        trim_to_range: Tuple[int, int] = [0, 128],
        normalize_hists: bool = False,
        normalize_hist_peaks: bool = False,
        subtract_dc_offset_from_real: bool = False,
    ) -> None:
        """
        Dataset for 6D pose estimation. Input is a set of histograms, output is a 6D pose.

        Args:
            dset_path (str): Path to the dataset - can be a real dataset, in which case this is a
                path to a folder containing subfolders with each capture. Or a simulated dataset,
                in which case this is a path to a .npz file, as generated by gen_sim_dataset.py.
            dset_type (str): Type of the dataset. Must be "real" or "sim".
            split (str): Split of the dataset to use. Must be "train", "test", or "all".
            test_portion (float): Proportion of the dataset to use for testing. Only used if split
                is "train" or "test".
            trim_to_range (Tuple[int, int]): Range to trim the histograms to.
            normalize_hists (bool): Whether to normalize the histograms to have an area under the
                curve of 1.
            normalize_hist_peaks (bool): Whether to normalize the histograms to have a peak of 1.
            subtract_dc_offset_from_real (bool): Whether to remove the DC offset from the histograms.
                Applies to real data only.
        """

        assert split in ["train", "test", "all"]
        assert not (normalize_hists and normalize_hist_peaks)

        self.dset_path = dset_path
        self.dset_type = dset_type
        self.split = split

        if self.dset_type == "real":
            if not os.path.isdir(dset_path):
                raise ValueError(
                    f"Invalid dataset path {dset_path} - must be a directory if dset_type is real"
                )
        elif self.dset_type == "sim":
            if not dset_path.endswith(".npz"):
                raise ValueError(
                    f"Invalid dataset path {dset_path} - must be a .npz file if dset_type is sim"
                )

        if self.dset_type == "sim":
            with open(dset_path, "rb") as f:
                data = np.load(f)
                self.histograms = data["histograms"]  # (n_samples, n_cameras, n_bins)
                self.object_poses = data["object_poses"]  # (n_samples, 4, 4) (homog. matrix)

        elif self.dset_type == "real":
            self.histograms = []
            self.object_poses = []
            self.filenames = []

            capture_folders = [
                f for f in os.listdir(dset_path) if os.path.isdir(os.path.join(dset_path, f))
            ]

            for capture_folder in capture_folders:
                # TODO: the first 6 real data can fit well, but the rest will have one histogram that does not match, need to check

                with open(os.path.join(dset_path, capture_folder, "tmf.json"), "r") as f:
                    tmf_data = json.load(f)

                this_capture_pooled_hist = (
                    np.array([m["hists"] for m in tmf_data]).sum(axis=1)[None, :] / 4000000
                )

                if subtract_dc_offset_from_real:
                    this_capture_pooled_hist = this_capture_pooled_hist - get_dc_offset(this_capture_pooled_hist)

                gt_pose_data = np.load(os.path.join(dset_path, capture_folder, "gt", "gt_pose.npy"))
                this_capture_poses = gt_pose_data[None, :]

                self.histograms.append(this_capture_pooled_hist)
                self.object_poses.append(this_capture_poses)
                self.filenames.append(capture_folder)

            self.histograms = np.concatenate(self.histograms, axis=0)
            self.object_poses = np.concatenate(self.object_poses, axis=0)

        # select data according to split
        # set the random seed for reproducibility
        np.random.seed(RANDOM_SPLIT_SEED)
        n_samples = self.histograms.shape[0]
        n_test = int(n_samples * test_portion)
        all_indices = np.arange(n_samples)
        np.random.shuffle(all_indices)
        test_indices = all_indices[:n_test]
        train_indices = all_indices[n_test:]

        # trim histograms to specified range. If range is [0, 128], nothing happens
        self.histograms = self.histograms[:, :, trim_to_range[0] : trim_to_range[1]]

        if normalize_hists:
            self.histograms = self.histograms / self.histograms.sum(axis=-1, keepdims=True)
        elif normalize_hist_peaks:
            self.histograms = self.histograms / self.histograms.max(axis=-1, keepdims=True)

        if self.split == "train":
            self.histograms = self.histograms[train_indices]
            self.object_poses = self.object_poses[train_indices]
        elif self.split == "test":
            self.histograms = self.histograms[test_indices]
            self.object_poses = self.object_poses[test_indices]
        # if split is all, keep histograms and object poses complete

        if self.dset_type == "real":
            if self.split == "train":
                self.filenames = [self.filenames[i] for i in train_indices]
            elif self.split == "test":
                self.filenames = [self.filenames[i] for i in test_indices]
            # if split is all, keep filenames complete

    def __len__(self) -> int:
        return self.histograms.shape[0]

    def __getitem__(self, idx: int) -> dict:
        if self.dset_type == "real":
            return self.histograms[idx], self.object_poses[idx], self.filenames[idx]
        else:
            return self.histograms[idx], self.object_poses[idx]
