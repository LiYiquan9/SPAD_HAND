import json
import os

import numpy as np
import torch
from torch.utils.data import DataLoader, Dataset

RANDOM_SPLIT_SEED = 0


class PoseEstimation6DDataset(Dataset):
    def __init__(
        self,
        dset_path: str,
        dset_type: str,
        split: str,
        test_portion: float = 0.2,
        subsample_n_test_samples: int = 0,
        include_hist_idxs: list | str = "all",
    ) -> None:
        """
        Dataset for 6D pose estimation. Input is a set of histograms, output is a 6D pose.

        Args:
            dset_path (str): Path to the dataset - can be a real dataset, in which case this is a
                path to a folder containing subfolders with each capture. Or a simulated dataset,
                in which case this is a path to a .npz file, as generated by gen_sim_dataset.py.
            dset_type (str): Type of the dataset. Must be "real" or "sim".
            split (str): Split of the dataset to use. Must be "train", "test", or "all".
            test_portion (float, optional): Proportion of the dataset to use for testing.
            subsample_n_test_samples (int, optional): If > 0, only use this many test samples, the
                rest will be discarded. Useful for faster eval.
            include_hist_idxs (list, optional): If a list, only include the histograms at these
                indices.
        """

        assert split in ["train", "test", "all"]
        assert type(include_hist_idxs) == list or include_hist_idxs == "all"

        self.dset_path = dset_path
        self.dset_type = dset_type
        self.split = split

        if self.dset_type == "real":
            if not os.path.isdir(dset_path):
                raise ValueError(
                    f"Invalid dataset path {dset_path} - must be a directory if dset_type is real"
                )
        elif self.dset_type == "sim":
            if not dset_path.endswith(".npz"):
                raise ValueError(
                    f"Invalid dataset path {dset_path} - must be a .npz file if dset_type is sim"
                )

        if self.dset_type == "sim":
            with open(dset_path, "rb") as f:
                data = np.load(f)
                self.histograms = data["histograms"]  # (n_samples, n_cameras, n_bins)
                self.object_poses = data["object_poses"]  # (n_samples, 4, 4) (homog. matrix)

        elif self.dset_type == "real":
            self.histograms = []
            self.object_poses = []
            self.filenames = []

            capture_folders = sorted(
                [f for f in os.listdir(dset_path) if os.path.isdir(os.path.join(dset_path, f))],
                key=lambda x: int(x),
            )

            for capture_folder in capture_folders:
                with open(os.path.join(dset_path, capture_folder, "tmf.json"), "r") as f:
                    tmf_data = json.load(f)

                this_capture_histograms = (
                    np.array([m["hists"] for m in tmf_data]).sum(axis=1)[None, :] * 0.00000035
                    - 0.0006
                )

                gt_pose_data = np.load(os.path.join(dset_path, capture_folder, "gt", "gt_pose.npy"))
                this_capture_poses = gt_pose_data[None, :]
                # this_capture_poses[0,2,3] -= 0.012 # re-align plane and object on z-axis

                self.histograms.append(this_capture_histograms)
                self.object_poses.append(this_capture_poses)
                self.filenames.append(capture_folder)

            self.histograms = np.concatenate(self.histograms, axis=0)
            self.object_poses = np.concatenate(self.object_poses, axis=0)

        # exclude certain histograms if necessary
        if include_hist_idxs != "all":
            assert all(0 <= idx < self.histograms.shape[0] for idx in include_hist_idxs)
            assert len(include_hist_idxs) > 0
            assert len(include_hist_idxs) < self.histograms.shape[0]
            assert list(set(include_hist_idxs)) == include_hist_idxs
            self.histograms = self.histograms[:, include_hist_idxs, :]

        # select data according to split
        # set the random seed for reproducibility
        np.random.seed(RANDOM_SPLIT_SEED)
        n_samples = self.histograms.shape[0]
        n_test = int(n_samples * test_portion)
        all_indices = np.arange(n_samples)
        np.random.shuffle(all_indices)
        test_indices = all_indices[:n_test]
        train_indices = all_indices[n_test:]

        if subsample_n_test_samples > 0:
            test_indices = test_indices[:subsample_n_test_samples]

        # remove background noise
        self.histograms[self.histograms < 1e-4] = 0

        # normalize within each histograms
        # means = self.histograms.mean(axis=-1, keepdims=True)
        # stds = self.histograms.std(axis=-1, keepdims=True)
        # self.histograms = (self.histograms - means) / stds

        if self.split == "train":
            self.histograms = self.histograms[train_indices]
            self.object_poses = self.object_poses[train_indices]
        elif self.split == "test":
            self.histograms = self.histograms[test_indices]
            self.object_poses = self.object_poses[test_indices]
        # if split is all, keep histograms and object poses complete

        if self.dset_type == "real":
            if self.split == "train":
                self.filenames = [self.filenames[i] for i in train_indices]
            elif self.split == "test":
                self.filenames = [self.filenames[i] for i in test_indices]
            # if split is all, keep filenames complete

    def __len__(self) -> int:
        return self.histograms.shape[0]

    def __getitem__(self, idx: int) -> dict:
        if self.dset_type == "real":
            return self.histograms[idx], self.object_poses[idx], self.filenames[idx]
        else:
            return self.histograms[idx], self.object_poses[idx]
